{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b985a",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# POI Data Enrichment with Google Maps Places API (New)\n",
    "\n",
    "This notebook enriches property data with Points of Interest (POI) using the Google Maps Places API v1 (New).\n",
    "\n",
    "- Uses the same POI category table (`realitky.cleaned.poi_category`) with `category_code` and `max_results`.\n",
    "- Selects properties to enrich from `realitky.cleaned.property` similarly to the Geoapify flow.\n",
    "- Calls `places.googleapis.com/v1/places:searchNearby` with an appropriate field mask and type mapping.\n",
    "- Transforms responses into the schema expected by `realitky.cleaned.property_poi` and upserts via MERGE.\n",
    "\n",
    "Notes:\n",
    "- Google Places v1 requires an API key and a Field Mask; this notebook requests a minimal set of fields.\n",
    "- Some Geoapify categories don't have a perfect Google type equivalent; a best-effort mapping is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70273f8c",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"api_key\", \"API_KEY\", \"Geoapify API Key\")\n",
    "dbutils.widgets.text(\"category_key\", \"1\", \"category_key\")\n",
    "dbutils.widgets.text(\"process_id\", \"manual\", \"Process ID\")\n",
    "dbutils.widgets.text(\"max_properties\", \"2\", \"Number of Records\")\n",
    "dbutils.widgets.dropdown(\"test_mode\", \"true\", [\"true\", \"false\"], \"Test Mode (limit to 5 records)\")\n",
    "\n",
    "\n",
    "# Get widget values\n",
    "api_key = dbutils.widgets.get(\"api_key\")\n",
    "category_key = int(dbutils.widgets.get(\"category_key\"))\n",
    "process_id = dbutils.widgets.get(\"process_id\")\n",
    "max_properties = int(dbutils.widgets.get(\"max_properties\"))\n",
    "\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"- API Key: {'*' * (len(api_key) - 4) + api_key[-4:] if len(api_key) > 4 else 'NOT_SET'}\")\n",
    "print(f\"- Categeory Key: {category_key}\")\n",
    "print(f\"- Process ID: {process_id}\")\n",
    "print(f\"- Number of properties: {max_properties}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc17664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select POI Category and properties to enrich\n",
    "row = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "      category_code_google,\n",
    "      max_results,\n",
    "      max_distance_m\n",
    "    FROM realitky.cleaned.poi_category \n",
    "    WHERE \n",
    "      category_key = {category_key} \n",
    "      AND del_flag = FALSE\n",
    "\"\"\").first()\n",
    "\n",
    "if row is None:\n",
    "    raise ValueError(f\"No category found for category_key={category_key}\")\n",
    "\n",
    "category_code = row['category_code_google']\n",
    "max_results_cfg = int(row['max_results']) if row['max_results'] is not None else 10\n",
    "radius_m = int(row['max_distance_m']) if row['max_distance_m'] is not None else 1000\n",
    "\n",
    "# Apply test_mode caps\n",
    "_test_mode = dbutils.widgets.get(\"test_mode\").lower() == \"true\"\n",
    "if _test_mode:\n",
    "    max_properties = min(max_properties, 5)\n",
    "    max_results_cfg = min(max_results_cfg, 5)\n",
    "\n",
    "print(f\"Category (google types str): {category_code}\")\n",
    "print(f\"Max results (per property): {max_results_cfg}\")\n",
    "print(f\"Radius (m): {radius_m}\")\n",
    "print(f\"Test mode: {_test_mode}\")\n",
    "\n",
    "df_properties_to_be_enriched = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "      property.property_id, \n",
    "      property.address_latitude, \n",
    "      property.address_longitude\n",
    "    FROM realitky.cleaned.property AS property\n",
    "    FULL OUTER JOIN realitky.stats.property_stats\n",
    "      ON property_stats.property_id = property.property_id \n",
    "     AND property_stats.src_web = property.src_web\n",
    "     AND property_stats.poi_places_check = TRUE\n",
    "     AND property_stats.del_flag = FALSE\n",
    "    WHERE \n",
    "      property.property_type_id IN (1, 2, 7, 15)\n",
    "      AND property.address_latitude > 0\n",
    "      AND property.address_longitude > 0\n",
    "      AND property.del_flag = FALSE\n",
    "    ORDER BY\n",
    "      property_stats.ins_dt DESC,\n",
    "      property_stats.upd_dt    \n",
    "    LIMIT {max_properties}\n",
    "\"\"\")\n",
    "display(df_properties_to_be_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6bd410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download POI data from Google Maps Places API v1 (Nearby Search)\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from pyspark.sql.types import StructType\n",
    "from datetime import datetime\n",
    "\n",
    "# Google Places API v1 Nearby Search endpoint\n",
    "BASE_URL = 'https://places.googleapis.com/v1/places:searchNearby'\n",
    "\n",
    "# Parse google types: category_code may be a comma-separated string\n",
    "if category_code is None or str(category_code).strip() == \"\":\n",
    "    included_types = []\n",
    "else:\n",
    "    included_types = [t.strip() for t in str(category_code).split(',') if t.strip()]\n",
    "\n",
    "# Build the request body for Nearby Search v1\n",
    "# radius in meters from table; max_results_cfg limits number of returned results.\n",
    "body_template = {\n",
    "    \"includedTypes\": included_types,\n",
    "    \"maxResultCount\": int(max_results_cfg) if max_results_cfg else 10,\n",
    "    \"rankPreference\": \"DISTANCE\"\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Goog-Api-Key': api_key,\n",
    "    # Keep a conservative FieldMask with known-valid fields\n",
    "    'X-Goog-FieldMask': \",\".join([\n",
    "        \"places.id\",\n",
    "        \"places.displayName\",\n",
    "        \"places.location\",\n",
    "        \"places.shortFormattedAddress\",\n",
    "        \"places.types\",\n",
    "        \"places.distanceMeters\",\n",
    "        \"places.googleMapsUri\"\n",
    "    ])\n",
    "}\n",
    "\n",
    "all_pois = []\n",
    "\n",
    "prop_count = df_properties_to_be_enriched.count()\n",
    "print(f\"Getting POIs for {prop_count} properties; includedTypes: {included_types}\")\n",
    "\n",
    "for idx, row in enumerate(df_properties_to_be_enriched.collect(), 1):\n",
    "    property_id = row['property_id']\n",
    "    address_latitude = float(row['address_latitude'])\n",
    "    address_longitude = float(row['address_longitude'])\n",
    "    body = dict(body_template)\n",
    "    body[\"locationRestriction\"] = {\n",
    "        \"circle\": {\n",
    "            \"center\": {\"latitude\": address_latitude, \"longitude\": address_longitude},\n",
    "            \"radius\": float(radius_m)\n",
    "        }\n",
    "    }\n",
    "    print(f\"Requesting Google Places for property_id='{property_id}' at ({address_latitude}, {address_longitude}) with includedTypes={included_types}\")\n",
    "    try:\n",
    "        response = requests.post(BASE_URL, headers=headers, data=json.dumps(body), timeout=10)\n",
    "        response.raise_for_status()\n",
    "        poi_data = response.json()\n",
    "        all_pois.append({\n",
    "            \"property_id\": property_id,\n",
    "            \"category_key\": category_key,\n",
    "            \"poi_raw_response\": json.dumps(poi_data, ensure_ascii=False)\n",
    "        })\n",
    "        places_count = len(poi_data.get('places', []))\n",
    "        print(f\"Success for property_id={property_id}, found {places_count} POIs.\")\n",
    "        time.sleep(0.1)\n",
    "    except requests.exceptions.Timeout as e:\n",
    "        print(f\"TIMEOUT for property {property_id}: {e}\\nBody: {body}\")\n",
    "        continue\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTPError for property {property_id}: {e}\\nStatus: {getattr(e.response, 'status_code', None)}\")\n",
    "        try:\n",
    "            print(f\"Response: {e.response.text[:500]}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error for property {property_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Finished POI download. Total successful: {len(all_pois)}\")\n",
    "\n",
    "if len(all_pois) > 0:\n",
    "    df_all_pois = spark.createDataFrame(all_pois)\n",
    "    display(df_all_pois)\n",
    "else:\n",
    "    df_all_pois = None\n",
    "    print(\"No POIs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a835d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POI Data Cleaning and Transformation\n",
    "import json\n",
    "from pyspark.sql.functions import from_json, col, explode_outer, schema_of_json, element_at, current_timestamp, lit, concat, udf, trim, when\n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "\n",
    "def _is_not_none_df(x):\n",
    "    try:\n",
    "        return x is not None\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "if _is_not_none_df(df_all_pois):\n",
    "    # UDFs to extract fields from Places v1 response for fallback name/address\n",
    "    def extract_field(json_str, path_list):\n",
    "        try:\n",
    "            obj = json.loads(json_str)\n",
    "            places = obj.get('places', [])\n",
    "            for place in places:\n",
    "                cur = place\n",
    "                for p in path_list:\n",
    "                    if isinstance(cur, dict) and p in cur:\n",
    "                        cur = cur[p]\n",
    "                    else:\n",
    "                        cur = None\n",
    "                        break\n",
    "                if cur is not None:\n",
    "                    return cur\n",
    "            return None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    extract_name_udf = udf(lambda x: extract_field(x, ['displayName', 'text']), StringType())\n",
    "    extract_address1_udf = udf(lambda x: extract_field(x, ['shortFormattedAddress']), StringType())\n",
    "    # address2 may be absent due to trimmed FieldMask; keep nullable\n",
    "    extract_address2_udf = udf(lambda x: extract_field(x, ['formattedAddress']), StringType())\n",
    "\n",
    "    # Infer schema from a sample\n",
    "    sample_row = df_all_pois.select(\"poi_raw_response\").filter(col(\"poi_raw_response\").isNotNull()).first()\n",
    "    if sample_row is not None:\n",
    "        sample_json = sample_row[\"poi_raw_response\"]\n",
    "        inferred_schema = schema_of_json(sample_json)\n",
    "    else:\n",
    "        inferred_schema = schema_of_json('{}')\n",
    "\n",
    "    # Parse JSON and explode\n",
    "    df = df_all_pois.withColumn(\"json\", from_json(col(\"poi_raw_response\"), inferred_schema))\n",
    "    df = df.withColumn(\"place\", explode_outer(col(\"json.places\")))\n",
    "\n",
    "    # Fallback extracted fields\n",
    "    df = df.withColumn(\"poi_name\", extract_name_udf(col(\"poi_raw_response\")))\n",
    "    df = df.withColumn(\"poi_address1\", extract_address1_udf(col(\"poi_raw_response\")))\n",
    "    df = df.withColumn(\"poi_address2\", extract_address2_udf(col(\"poi_raw_response\")))\n",
    "\n",
    "    # Build URL if not provided\n",
    "    google_uri_col = col(\"place.googleMapsUri\")\n",
    "    lat_col = col(\"place.location.latitude\")\n",
    "    lng_col = col(\"place.location.longitude\")\n",
    "    poi_url_expr = concat(lit(\"https://www.google.com/maps/search/?api=1&query=\"), lat_col.cast(StringType()), lit(\",\"), lng_col.cast(StringType()))\n",
    "\n",
    "    df_final = df.select(\n",
    "        col(\"category_key\"),\n",
    "        col(\"property_id\"),\n",
    "        col(\"place\").cast(StringType()).alias(\"poi_attributes\"),\n",
    "        lat_col.alias(\"poi_latitude\"),\n",
    "        lng_col.alias(\"poi_longitude\"),\n",
    "        col(\"poi_name\"),\n",
    "        col(\"place.id\").alias(\"poi_id\"),\n",
    "        col(\"place.distanceMeters\").alias(\"poi_distance_m\"),\n",
    "        col(\"poi_address1\"),\n",
    "        col(\"poi_address2\"),\n",
    "        lit(\"google\").alias(\"data_source\"),\n",
    "        when(google_uri_col.isNotNull(), google_uri_col).otherwise(poi_url_expr).alias(\"poi_url\"),\n",
    "        current_timestamp().alias(\"ins_dt\"),\n",
    "        lit(process_id).alias(\"ins_process_id\"),\n",
    "        current_timestamp().alias(\"upd_dt\"),\n",
    "        lit(process_id).alias(\"upd_process_id\"),\n",
    "        lit(False).alias(\"del_flag\")\n",
    "    )\n",
    "\n",
    "    df_final = df_final.filter(~((trim(col(\"poi_attributes\")) == \"{}\") | (col(\"poi_attributes\").isNull())))\n",
    "    display(df_final)\n",
    "else:\n",
    "    print(\"No POIs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write POIs to realitky.cleaned.property_poi partitioned by category_key\n",
    "if df_all_pois is not None:\n",
    "    df_final.createOrReplaceTempView(\"tmp_property_poi\")\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO realitky.cleaned.property_poi AS target\n",
    "        USING tmp_property_poi AS source\n",
    "        ON target.property_id = source.property_id\n",
    "            AND target.category_key = source.category_key\n",
    "            AND target.poi_id = source.poi_id\n",
    "        WHEN MATCHED \n",
    "            AND target.category_key = {category_key}\n",
    "            AND (\n",
    "                target.poi_attributes <> source.poi_attributes OR\n",
    "                target.del_flag <> source.del_flag\n",
    "            )\n",
    "        THEN UPDATE SET\n",
    "            target.poi_attributes = source.poi_attributes,\n",
    "            target.poi_latitude = source.poi_latitude,\n",
    "            target.poi_longitude = source.poi_longitude,\n",
    "            target.poi_name = source.poi_name,\n",
    "            target.poi_distance_m = source.poi_distance_m,\n",
    "            target.poi_address1 = source.poi_address1,\n",
    "            target.poi_address2 = source.poi_address2,\n",
    "            target.data_source = source.data_source,\n",
    "            target.poi_url = source.poi_url,\n",
    "            target.upd_dt = source.upd_dt,\n",
    "            target.upd_process_id = source.upd_process_id,\n",
    "            target.del_flag = source.del_flag\n",
    "        WHEN NOT MATCHED\n",
    "            AND source.category_key = {category_key}\n",
    "        THEN INSERT(\n",
    "            category_key,\n",
    "            property_id,\n",
    "            poi_attributes,\n",
    "            poi_latitude,\n",
    "            poi_longitude,\n",
    "            poi_name,\n",
    "            poi_id,\n",
    "            poi_distance_m,\n",
    "            poi_address1,\n",
    "            poi_address2,\n",
    "            data_source,\n",
    "            poi_url,\n",
    "            ins_dt,\n",
    "            ins_process_id,\n",
    "            upd_dt,\n",
    "            upd_process_id,\n",
    "            del_flag\n",
    "        ) VALUES(\n",
    "            source.category_key,\n",
    "            source.property_id,\n",
    "            source.poi_attributes,\n",
    "            source.poi_latitude,\n",
    "            source.poi_longitude,\n",
    "            source.poi_name,\n",
    "            source.poi_id,\n",
    "            source.poi_distance_m,\n",
    "            source.poi_address1,\n",
    "            source.poi_address2,\n",
    "            source.data_source,\n",
    "            source.poi_url,\n",
    "            source.ins_dt,\n",
    "            source.ins_process_id,\n",
    "            source.upd_dt,\n",
    "            source.upd_process_id,\n",
    "            source.del_flag\n",
    "        )\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\"No POIs found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
