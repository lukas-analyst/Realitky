{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3360ca1c-0f0a-4278-8929-7d3158a7651d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb1c55e-52b7-42e0-956c-1aa0f5a6f81b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install aiohttp>=3.8.0 aiofiles>=22.1.0 httpx>=0.24.0 selectolax>=0.3.0 nbformat>=5.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5ca0a63-b312-4510-97d1-4ee790d624cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"scraper_name\", \"bezrealitky\")\n",
    "dbutils.widgets.text(\"process_id\", \"0Z\")\n",
    "\n",
    "scraper_name = dbutils.widgets.get(\"scraper_name\")\n",
    "input_table_name = f\"realitky.raw.listings_{scraper_name}\"\n",
    "output_table_name = f\"realitky.raw.listing_details_{scraper_name}\"\n",
    "output_images_table_name = f\"realitky.raw.listing_images_{scraper_name}\"\n",
    "\n",
    "process_id = dbutils.widgets.get(\"process_id\")\n",
    "insert_mode = \"append\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d70fa0e0-7a82-46f0-996d-155ae802a17c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Load data from table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "669a8e3c-2a2c-462b-b7a4-2d991ba5fb23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(f\"SELECT listing_id, listing_url FROM {input_table_name} WHERE parsed = false AND del_flag = false\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bf1eef4-947f-4041-b7af-0aa57cf80bec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Prepare parsing script\n",
    "Contains:\n",
    "- details (dictionary) + listing_hash\n",
    "- images (list) + images_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5d2c526-c7bd-4e2e-9689-9917ddb46575",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"image_urls\":828},\"columnVisibility\":{}},\"settings\":{\"columns\":{\"image_urls\":{\"format\":{\"preset\":\"string-preset-url\"}},\"listing_url\":{\"format\":{\"preset\":\"string-preset-url\"}}}},\"syncTimestamp\":1754470144859}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      },
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"img_link\":1025},\"columnVisibility\":{}},\"settings\":{\"columns\":{\"img_link\":{\"format\":{\"preset\":\"string-preset-url\"}}}},\"syncTimestamp\":1754470584765}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import httpx\n",
    "import hashlib\n",
    "import json\n",
    "from selectolax.parser import HTMLParser\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from typing import Optional, Dict, Tuple, List\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "\n",
    "class Scraper_details:\n",
    "    def extract_direct_image_url(self, next_image_url: str) -> str:\n",
    "        \"\"\"Extract direct image URL from Next.js image wrapper\"\"\"\n",
    "        try:\n",
    "            parsed_url = urlparse(next_image_url)\n",
    "            if parsed_url.path == '/_next/image' and 'url' in parse_qs(parsed_url.query):\n",
    "                # Extract the actual image URL from the 'url' parameter\n",
    "                direct_url = parse_qs(parsed_url.query)['url'][0]\n",
    "                return unquote(direct_url)\n",
    "            else:\n",
    "                # If it's not a Next.js wrapper, return as is\n",
    "                return next_image_url\n",
    "        except:\n",
    "            return next_image_url\n",
    "\n",
    "    async def fetch_property_details(self, listing_id: str, listing_url: str) -> Tuple[Optional[Dict], List[Dict]]:\n",
    "        try:\n",
    "            url = listing_url\n",
    "            async with httpx.AsyncClient(follow_redirects=True, timeout=30.0) as client:\n",
    "                try:\n",
    "                    response = await client.get(url)\n",
    "                    response.raise_for_status()\n",
    "                except httpx.HTTPStatusError as e:\n",
    "                    print(f\"Error fetching {listing_id}: {e} (HTTP error)\")\n",
    "                    return None, []\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching {listing_id}: {e}\")\n",
    "                    return None, []\n",
    "\n",
    "                parser = HTMLParser(response.text)\n",
    "\n",
    "            details = {\n",
    "                \"listing_id\": str(listing_id),\n",
    "                \"listing_url\": str(listing_url)\n",
    "            }\n",
    "\n",
    "            title_element = parser.css_first(\"h1.h2.pd-header__title, h1.h2, h1.mb-3.mb-lg-10.h2\")\n",
    "            if title_element:\n",
    "                span_element = title_element.css_first(\"span\")\n",
    "                details[\"Property Name\"] = str(span_element.text(strip=True))\n",
    "\n",
    "            description_container = parser.css_first('div[id^=\"react-aria-\"][id$=\"-tabpane-native\"]')\n",
    "            if description_container:\n",
    "                details[\"Property Description\"] = str(description_container.text(strip=True))\n",
    "\n",
    "            # Price (Sale)\n",
    "            price_container = parser.css_first(\"div.justify-content-between.align-items-baseline.mb-lg-9.mb-6.row\")\n",
    "            if price_container:\n",
    "                price_span = price_container.css_first(\"strong.h4.fw-bold span\")\n",
    "                if price_span:\n",
    "                    details[\"Cena\"] = price_span.text(strip=True)\n",
    "            \n",
    "            # Price (Rent)\n",
    "            price_container_alt = parser.css_first(\"div.justify-content-between.align-items-baseline.row\")\n",
    "            if price_container_alt:\n",
    "                price_span_alt = price_container_alt.css_first(\"strong.h4.fw-bold span\")\n",
    "                if price_span_alt:\n",
    "                    details[\"Cena\"] = price_span_alt.text(strip=True)\n",
    "\n",
    "            # Price details\n",
    "            price_details_caontainer = parser.css_first(\"div.justify-content-between.mb-2.mb-last-0.row\")\n",
    "            if price_details_caontainer:\n",
    "                details[\"Price details\"] = str(price_details_caontainer.text(strip=True))\n",
    "                \n",
    "            # Category\n",
    "            category_element = parser.css_first(\"nav[aria-label='breadcrumb'] ol.breadcrumb\")\n",
    "            if category_element:\n",
    "                category_texts = [\n",
    "                    li.text(strip=True)\n",
    "                    for li in category_element.css(\"li.breadcrumb-item\")\n",
    "                    if li.text(strip=True) and \"Domů\" not in li.text(strip=True)\n",
    "                ]\n",
    "                # Remove the first element (\"Výpis nemovitostí\") if present\n",
    "                if category_texts and category_texts[0] == \"Výpis nemovitostí\":\n",
    "                    category_texts = category_texts[1:]\n",
    "                \n",
    "                # Get Category\n",
    "                details[\"Category\"] = \",\".join(category_texts) if category_texts else \"XNA\"\n",
    "                \n",
    "                # Dynamically assign category fields\n",
    "                if category_texts:\n",
    "                    for idx, val in enumerate(category_texts, 1):\n",
    "                        details[f\"category_{idx}\"] = val\n",
    "\n",
    "            # Additional property details\n",
    "            details_container = parser.css(\"div.ParamsTable_paramsTable__tX8zj.paramsTable\")\n",
    "            if details_container:\n",
    "                for detail_container in details_container:\n",
    "                    for tr in detail_container.css(\"tr\"):\n",
    "                        th = tr.css_first(\"th span\")\n",
    "                        td = tr.css_first(\"td\")\n",
    "                        if th and td:\n",
    "                            label = th.text(strip=True)\n",
    "                            value_span = td.css_first(\"span\")\n",
    "                            value = value_span.text(strip=True) if value_span else td.text(strip=True)\n",
    "                            details[label] = str(value)\n",
    "\n",
    "            # GPS coordinates\n",
    "            next_data_script = parser.css_first('script#__NEXT_DATA__')\n",
    "            if next_data_script:\n",
    "                try:\n",
    "                    data = json.loads(next_data_script.text())\n",
    "                    gps = data.get(\"props\", {}) \\\n",
    "                            .get(\"pageProps\", {}) \\\n",
    "                            .get(\"origAdvert\", {}) \\\n",
    "                            .get(\"gps\", {})\n",
    "                    lat = gps.get(\"lat\")\n",
    "                    lng = gps.get(\"lng\")\n",
    "                    details[\"GPS coordinates\"] = str(f\"{lat},{lng}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Set status\n",
    "            inactive_element = parser.css_first('section.box.Section_section__gjwvr.section.mb-0.py-10.py-xl-25 h1.mb-5.mb-lg-10.h1.text-center span')\n",
    "            if inactive_element and inactive_element.text(strip=True) == \"Inzerát již není v nabídce\":\n",
    "                details[\"Status\"] = \"inactive\"\n",
    "            else:\n",
    "                details[\"Status\"] = \"active\"\n",
    "            \n",
    "            # Generate listing_hash\n",
    "            detail_hash_input = {k: v for k, v in details.items()}\n",
    "            listing_hash = hashlib.sha256(str(sorted(detail_hash_input.items())).encode()).hexdigest()\n",
    "            details[\"listing_hash\"] = str(listing_hash)\n",
    "\n",
    "            \n",
    "            #######################\n",
    "            ##### -- IMAGES -- ####\n",
    "            #######################\n",
    "            \n",
    "            # Extract property images - separate structure\n",
    "            images = []\n",
    "            images_container = parser.css(\"div.PropertyCarousel_propertyCarouselSlide__BPboJ\")\n",
    "            if images_container:\n",
    "                for img_number, slide in enumerate(images_container, 1):\n",
    "                    img_element = slide.css_first(\"img\")\n",
    "                    if img_element:\n",
    "                        src = img_element.attributes.get(\"src\")\n",
    "\n",
    "                        if src:\n",
    "                            # Handle relative URLs\n",
    "                            if src.startswith(\"//\"):\n",
    "                                src = \"https:\" + src\n",
    "                            elif src.startswith(\"/\"):\n",
    "                                src = \"https://www.bezrealitky.cz\" + src\n",
    "                            \n",
    "                            # Extract direct image URL\n",
    "                            direct_url = self.extract_direct_image_url(src)\n",
    "                            \n",
    "                            # Create image record\n",
    "                            image_record = {\n",
    "                                \"listing_id\": str(listing_id),\n",
    "                                \"img_number\": img_number,\n",
    "                                \"img_link\": str(direct_url)\n",
    "                            }\n",
    "                            images.append(image_record)\n",
    "            else:\n",
    "                # No images found, push listing_id and leave other columns as None\n",
    "                image_record = {\n",
    "                    \"listing_id\": str(listing_id),\n",
    "                    \"img_number\": None,\n",
    "                    \"img_link\": None\n",
    "                }\n",
    "                images.append(image_record)\n",
    "            \n",
    "            # Generate images_hash\n",
    "            image_hash_input = str(sorted([sorted(img.items()) for img in images]))\n",
    "            images_hash = hashlib.sha256(image_hash_input.encode()).hexdigest()\n",
    "            for image_record in images:\n",
    "                image_record[\"images_hash\"] = str(images_hash)\n",
    "            \n",
    "            print(f\"Found {len(images)} images for listing {listing_id}\")\n",
    "            return details, images\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {listing_id}: {e}\")\n",
    "            return None, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adb79544-d8ec-44f2-9f79-c23313e59a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Execute parsing\n",
    "- Run the parsing script to extract relevant data from the raw input.\n",
    "- Ensure all required fields are captured and formatted correctly.\n",
    "- Log any errors or missing data for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b40a1c5e-20fe-4904-a566-550179a7478c",
     "showTitle": false,
     "tableResultSettingsMap": {
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"img_link\":252},\"columnVisibility\":{}},\"settings\":{\"columns\":{\"img_link\":{\"format\":{\"preset\":\"string-preset-url\"}}}},\"syncTimestamp\":1754473808275}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Execute the async function\n",
    "print(f\"Found {df.count()} listings\")\n",
    "if df.count() > 0:\n",
    "    scraper = Scraper_details()\n",
    "    results = await asyncio.gather(*[scraper.fetch_property_details(row.listing_id, row.listing_url) for row in df.collect()])\n",
    "    \n",
    "    # Separate details and images\n",
    "    parsed_details = [result[0] for result in results if result[0] is not None] # results = [0, 1]\n",
    "    parsed_images = []\n",
    "    for result in results:\n",
    "        if result[1]:\n",
    "            parsed_images.extend(result[1])\n",
    "    \n",
    "    print(f\"Scraped {len(parsed_details)} listings with {len(parsed_images)} total images\")\n",
    "    \n",
    "    # Create DataFrames\n",
    "    if parsed_details:\n",
    "        df_parsed_details = spark.createDataFrame(parsed_details)\n",
    "    else:\n",
    "        schema = StructType([\n",
    "            StructField(\"listing_id\", StringType(), True),\n",
    "            StructField(\"listing_url\", StringType(), True)\n",
    "        ])\n",
    "        df_parsed_details = spark.createDataFrame([], schema)\n",
    "    \n",
    "    if parsed_images:\n",
    "        df_parsed_images = spark.createDataFrame(parsed_images)\n",
    "    else:\n",
    "        images_schema = StructType([\n",
    "            StructField(\"listing_id\", StringType(), True),\n",
    "            StructField(\"img_number\", StringType(), True),\n",
    "            StructField(\"img_link\", StringType(), True)\n",
    "        ])\n",
    "        df_parsed_images = spark.createDataFrame([], images_schema)\n",
    "\n",
    "print(\"--- DETAILS ---\")\n",
    "display(df_parsed_details)\n",
    "print(\"--- IMAGES ---\")\n",
    "display(df_parsed_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c2dd550-0c60-4c90-97a8-47126e0f3b36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Export data and update stats\n",
    "- From 'clean_column_name.ipynb. get script for cleaning names of columns (eg. no diacritics, lowercase, replace spaces with underscore, etc.)\n",
    "- From 'listing_details_import.ipynb' get script for importing scraped information about property\n",
    "- From 'listing_update.ipynb' get script for updating state of listing_id to be 'parsed = True'\n",
    "- After all get all the listing_ids and set upd_check_date to current date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08c0e122-e8d5-4ffc-aee3-ca4f26a4d14b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql.functions import current_date\n",
    "\n",
    "# import functions\n",
    "%run \"./utils/clean_column_name.ipynb\"\n",
    "%run \"./utils/listing_details_import.ipynb\"\n",
    "%run \"./utils/listings_update.ipynb\"\n",
    "\n",
    "if df_parsed_details.count() > 0:\n",
    "    # Clean column names\n",
    "    df_parsed_details = clean_column_names(df_parsed_details)\n",
    "    df_parsed_images = clean_column_names(df_parsed_images)\n",
    "\n",
    "    # Export scraped data about property\n",
    "    row_count = export_to_table(df_parsed_details, output_table_name, insert_mode, \"listing_hash\")\n",
    "    images_count = export_to_table(df_parsed_images, output_images_table_name, insert_mode, \"images_hash\")\n",
    "\n",
    "    # Update all listing_ids with 'parsed = True'\n",
    "    df_parsed_details.createOrReplaceTempView(\"listing_ids_view\")\n",
    "    update_listings(input_table_name, 'parsed', process_id)\n",
    "\n",
    "    # Update input table with 'upd_check_date = current_date'\n",
    "    spark.sql(f\"\"\"    \n",
    "        UPDATE {input_table_name}\n",
    "            SET upd_check_date = current_date()\n",
    "            WHERE listing_id IN (SELECT listing_id FROM listing_ids_view) AND del_flag = false\n",
    "        \"\"\")\n",
    "else:\n",
    "    row_count = 0\n",
    "\n",
    "# Save row count\n",
    "dbutils.jobs.taskValues.set(\"row_count\", row_count)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7452526412662602,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "scraper_bezrealitky_detail",
   "widgets": {
    "process_id": {
     "currentValue": "0Z",
     "nuid": "e18bbb97-8a57-4b85-ac1d-8161329a2e10",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "0Z",
      "label": null,
      "name": "process_id",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "0Z",
      "label": null,
      "name": "process_id",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "scraper_name": {
     "currentValue": "bezrealitky",
     "nuid": "22a099b2-4f1e-4d56-9756-4dbad8babbbb",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "bezrealitky",
      "label": null,
      "name": "scraper_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "bezrealitky",
      "label": null,
      "name": "scraper_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
