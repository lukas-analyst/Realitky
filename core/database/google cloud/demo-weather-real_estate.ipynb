{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b1795-e897-490c-afb3-a7ff1812bc25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the necessary library to interact with BigQuery\n",
    "%pip install pandas-gbq\n",
    "%pip install --upgrade google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a1ff2-bbe9-4dcf-8e70-b04c1dc34a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "import bigframes.pandas as bf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Cloud Project\n",
    "project_id = \"adcz-adoki-poc\"\n",
    "location_id = \"europe-west1\"\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=project_id, location=location_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66009384-5d12-4b9b-b542-1ca0e50333c6",
   "metadata": {},
   "source": [
    "### Get data from BigQuery\n",
    "- using local/Workbanch computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f3b5c-c6c3-4856-bd80-19bd75b010cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use local computing power\n",
    "sql = \"SELECT property_id, address_latitude, address_longitude FROM subs_property_data.property WHERE address_latitude > 0\"\n",
    "df_property = bf.read_gbq(sql).head(10)\n",
    "\n",
    "display(df_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2504687b",
   "metadata": {},
   "source": [
    "### Historické počasí (včerejšek) pro GPS souřadnice\n",
    "Získáme denní metriky (max/min teplota, srážky) z Open-Meteo Archive API pro datum včera (časová zóna Europe/Prague)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import requests\n",
    "import pprint\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "\n",
    "# Připravíme unikátní souřadnice (předpoklad: sloupce address_latitude, address_longitude existují v df_property)\n",
    "coords_df = df_property[['address_latitude', 'address_longitude']].dropna().drop_duplicates().rename(columns={\n",
    "    'address_latitude': 'lat',\n",
    "    'address_longitude': 'lon'\n",
    "})\n",
    "\n",
    "# Definice hodinových parametrů podle dokumentace\n",
    "hourly_params = [\n",
    "    'temperature_2m',          # °C\n",
    "    'relative_humidity_2m',    # %\n",
    "    'rain',                    # mm\n",
    "    'snowfall',                # cm new snow (we will also try snow_depth if needed)\n",
    "    'snow_depth',              # snow depth (documentation: some APIs provide)\n",
    "    'windspeed_10m'            # km/h\n",
    "]\n",
    "\n",
    "hourly_results = []\n",
    "base_url_hourly = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "today = datetime.now()\n",
    "start_date = (today - timedelta(days=2)).date()\n",
    "end_date = start_date\n",
    "\n",
    "first_coord_debug_done = False\n",
    "for row in coords_df.itertuples(index=False):\n",
    "    lat, lon = row.lat, row.lon\n",
    "    params = {\n",
    "        'latitude': lat,\n",
    "        'longitude': lon,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'hourly': ','.join(hourly_params),\n",
    "        'timezone': 'Europe/Prague'\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(base_url_hourly, params=params, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        hourly = data.get('hourly')\n",
    "        if not hourly:\n",
    "            print(f\"⚠️ Chybí 'hourly' blok pro {lat},{lon}\")\n",
    "            continue\n",
    "        times = hourly.get('time', [])\n",
    "\n",
    "        # Debug pro první koordinát – zjistíme délky jednotlivých polí\n",
    "        if not first_coord_debug_done:\n",
    "            print(\"--- DEBUG první koordináty ---\")\n",
    "            print(\"Počet timestamps:\", len(times))\n",
    "            for p in hourly_params:\n",
    "                arr = hourly.get(p)\n",
    "                print(f\"{p}: length={len(arr) if isinstance(arr, list) else 'None'}\")\n",
    "            print(\"Ukázka prvních 5 timestamps:\", times[:5])\n",
    "            first_coord_debug_done = True\n",
    "\n",
    "        # Pokud některé pole má kratší délku než times, doplníme None a upozorníme\n",
    "        max_len = len(times)\n",
    "        normalized = {}\n",
    "        for p in hourly_params:\n",
    "            arr = hourly.get(p, []) or []\n",
    "            if len(arr) != max_len:\n",
    "                print(f\"⚠️ Varování: {p} má délku {len(arr)} != {max_len} (doplním None)\")\n",
    "                arr = (arr + [None] * max_len)[:max_len]\n",
    "            normalized[p] = arr\n",
    "\n",
    "        for i, ts in enumerate(times):\n",
    "            # Rozdělení na datum a hodinu (formát 'YYYY-MM-DDTHH:MM')\n",
    "            try:\n",
    "                date_part, time_part = ts.split('T')\n",
    "                hour_part = time_part.split(':')[0]\n",
    "            except ValueError:\n",
    "                continue\n",
    "            record = {\n",
    "                'lat': lat,\n",
    "                'lon': lon,\n",
    "                'date': date_part,\n",
    "                'hour': int(hour_part),\n",
    "                'temperature': normalized['temperature_2m'][i],\n",
    "                'relative_humidity': normalized['relative_humidity_2m'][i],\n",
    "                'rain': normalized['rain'][i],\n",
    "                'snow_depth': None,  # nastavíme níže\n",
    "                'wind_speed': normalized['windspeed_10m'][i],\n",
    "            }\n",
    "            # Sněh: preferuj snow_depth, fallback snowfall\n",
    "            if normalized['snow_depth'][i] is not None:\n",
    "                record['snow_depth'] = normalized['snow_depth'][i]\n",
    "            elif normalized['snowfall'][i] is not None:\n",
    "                record['snow_depth'] = normalized['snowfall'][i]\n",
    "\n",
    "            hourly_results.append(record)\n",
    "        # Krátká pauza mezi koordinátami (ne uvnitř hodin) pro šetrnost\n",
    "        time.sleep(0.15)\n",
    "\n",
    "    except Exception as e:  # noqa: BLE001\n",
    "        print(f\"Chyba (hourly) pro {lat},{lon}: {e}\")\n",
    "\n",
    "hourly_weather_df = pd.DataFrame(hourly_results)\n",
    "\n",
    "# Převod df_property na pandas + mapování lat/lon -> property_id (může být mnoho stejných souřadnic)\n",
    "prop_coord_map = df_property.to_pandas()[['property_id', 'address_latitude', 'address_longitude']].dropna()\n",
    "\n",
    "# Merge: mnohonásobné přiřazení property_id pro shodné souřadnice\n",
    "hourly_merged = hourly_weather_df.merge(\n",
    "    prop_coord_map,\n",
    "    left_on=['lat', 'lon'],\n",
    "    right_on=['address_latitude', 'address_longitude'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Výběr požadovaných sloupců a přejmenování\n",
    "final_hourly_df = hourly_merged[['property_id', 'date', 'hour', 'temperature', 'relative_humidity', 'rain', 'snow_depth', 'wind_speed']].copy()\n",
    "\n",
    "# Typové úpravy\n",
    "if not final_hourly_df.empty:\n",
    "    final_hourly_df['hour'] = final_hourly_df['hour'].astype(int)\n",
    "\n",
    "print(f\"Hodinových záznamů počasí celkem: {len(final_hourly_df)}\")\n",
    "\n",
    "display(final_hourly_df.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a5d78",
   "metadata": {},
   "source": [
    "### Import do BigQuery\n",
    "Target tabulka: 'property_weather'\n",
    "- if does not exist then create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Konfigurace ---\n",
    "project_id = \"adcz-adoki-poc\"  # pokud chceš dynamicky, můžeš načíst z env proměnné\n",
    "dataset_id = \"demo_real_estate\"\n",
    "table_id = \"property_weather\"\n",
    "full_table_id = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "# Ověření, že máme zdrojový DataFrame\n",
    "if 'final_hourly_df' not in globals():\n",
    "    raise RuntimeError(\"final_hourly_df neexistuje. Spusť nejprve sekci s hodinovými daty.\")\n",
    "\n",
    "# Kopie a úprava dat\n",
    "bq_df = final_hourly_df.copy()\n",
    "\n",
    "# Přidáme ingestion timestamp\n",
    "bq_df['ingested_at'] = datetime.utcnow()\n",
    "\n",
    "# Normalizace typů a NaN -> None\n",
    "for col in ['temperature','relative_humidity','rain','snow_depth','wind_speed']:\n",
    "    if col in bq_df.columns:\n",
    "        bq_df[col] = pd.to_numeric(bq_df[col], errors='coerce')\n",
    "\n",
    "# property_id jako string (pro konzistenci a aby se neztratily případné jiné formáty)\n",
    "if 'property_id' in bq_df.columns:\n",
    "    bq_df['property_id'] = bq_df['property_id'].astype(str)\n",
    "\n",
    "# hour integer\n",
    "if 'hour' in bq_df.columns:\n",
    "    bq_df['hour'] = bq_df['hour'].astype(int)\n",
    "\n",
    "# date na date objekt (pokud je string)\n",
    "if 'date' in bq_df.columns:\n",
    "    try:\n",
    "        bq_df['date'] = pd.to_datetime(bq_df['date']).dt.date\n",
    "    except Exception as e:  # noqa: BLE001\n",
    "        print(\"Varování: nepodařilo se konvertovat 'date' na date:\", e)\n",
    "\n",
    "bq_df = bq_df.where(pd.notnull(bq_df), None)\n",
    "\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# --- Dataset ---\n",
    "try:\n",
    "    client.get_dataset(f\"{project_id}.{dataset_id}\")\n",
    "    print(f\"Dataset '{dataset_id}' OK\")\n",
    "except NotFound:\n",
    "    dataset = bigquery.Dataset(f\"{project_id}.{dataset_id}\")\n",
    "    dataset.location = \"EU\"  # uprav dle potřeby\n",
    "    dataset = client.create_dataset(dataset)\n",
    "    print(f\"Vytvořen dataset: {dataset.full_dataset_id}\")\n",
    "\n",
    "# --- Tabulka ---\n",
    "try:\n",
    "    client.get_table(full_table_id)\n",
    "    table_exists = True\n",
    "    print(f\"Tabulka '{full_table_id}' existuje – data budou APPEND.\")\n",
    "except NotFound:\n",
    "    table_exists = False\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"property_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"date\", \"DATE\"),\n",
    "        bigquery.SchemaField(\"hour\", \"INT64\"),\n",
    "        bigquery.SchemaField(\"temperature\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"relative_humidity\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"rain\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"snow_depth\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"wind_speed\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"ingested_at\", \"TIMESTAMP\"),\n",
    "    ]\n",
    "    table = bigquery.Table(full_table_id, schema=schema)\n",
    "    table = client.create_table(table)\n",
    "    print(f\"Vytvořena tabulka: {table.full_table_id}\")\n",
    "\n",
    "# --- Load Job ---\n",
    "job_config = bigquery.LoadJobConfig(write_disposition=bigquery.WriteDisposition.WRITE_APPEND)\n",
    "\n",
    "load_job = client.load_table_from_dataframe(bq_df, full_table_id, job_config=job_config)\n",
    "print(\"Nahrávám data do BigQuery...\")\n",
    "load_job.result()  # čekáme na dokončení\n",
    "\n",
    "# Kontrola počtu řádků\n",
    "table = client.get_table(full_table_id)\n",
    "print(f\"Hotovo. Tabulka nyní obsahuje {table.num_rows} řádků.\")\n",
    "\n",
    "# Zobrazíme malý výřez\n",
    "display(bq_df.head())"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
